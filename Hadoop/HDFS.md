<br>

<div align="center">
    <img src="logo.jpg" width="200px">
</div>

<br>

1. **HDFS数据块** 
每个磁盘都有默认的数据块大小，这是磁盘进行数据读写的最小单位。构建于单个磁盘上的文件系统通过磁盘块来管理该文件系统中的块，一般来说文件系统的块大小是磁盘块的整数倍。文件系统块一般为几千字节，而磁盘块一般只有512字节。HDFS文件管理系统也有块的的概念，每个块大小为128M，这个块是独立的存储单元，但是与普通的文件系统不同的是，hdfs中小于一个块大小的文件不会占据整个块空间。之所以HDFS中的数据块设置的很大是为了最小化寻址开销。也就是说如果块足够大，那么从磁盘传输数据的时间会明显大于定义这个块所花费的时间。在此情况下，传输一个由多个块组成的大文件的时间取决于磁盘传输速率。但是同时这个参数也不会设置的太大，因为这会大大减少mapper的数量导致传输速度缓慢。设置文件分块是有很大的好处的，例如一个文件的大小可以大于网络中任意一个磁盘的容量，文件中的所有块并不需要存储在同一个磁盘上。第二个好处是，使用抽象块而非整个文件作为存储单元，大大的简化了存储子系统的设计。除此之外，文件分块还非常适合于数据备份进而提供数据容错能力和提高可用性。Hdfs fsck显示块信息。
2. **NameNode和DataNode**
NameNode是管理结点，它管理文件系统的命名空间，负责维护文件系统树和整个树内所有的文件和目录，这些信息以命名空间镜像文件和编辑日志文件永久的保存在本地磁盘上，于此同时，namenode也记录每个文件中各个块所在的数据结点信息。DataNode是工作结点，负责存储并检索数据块，并且定期向namenode报告自身存储的块信息。
NameNode的容错：NameNode的作用很大，如果一旦宕机，整个文件系统的文件都会丢失，因为我们不知道如何根据datanode的块重建文件信息。第一种容错机制是备份那些组成文件系统元数据持久状态的文件，一般来说在将持久状态写入本地磁盘的同时写入一个远程挂载的网络文件系统。另一种方法是构建一个辅助namenode。
3. **HDFS具备高可用性**
hadoop2.x通过配置一对活动-备用namenode来实现高可用性。当活动的namenode失效的时候，备用namenode会接管他的任务并且服务于来自客户端的请求，不会有明显的中断。为了实现这一点有如下几个要求应该被满足。
(1)namenode之间需要通过高可用共享存储来实现对编辑日志的共享。高可用共享存储可以使用NFS过滤器或者QJM。其中QJM以一组日志结点的形式运行，每次编辑必须写入多数日志结点，他没有使用zookeeper但是确实使用了其技术。
(2)datanode需要同时向两个namenode发送数据块处理报告，因此信息储存在内存中
(3)客户端需要一种机制来处理namenode失效问题
(4)备用namenode为活动的namenode设置周期性检查点。
4. **块缓存**
对于频繁访问的文件，其对应的块最好被显式的缓存在Datanode的内存中。通常来说一个数据块应该只被一个Datanode存储在内存中。这大大提高了系统性能。一般来说，用户通过在缓冲池中增加一个cache directive来告诉namenode需要缓存哪些文件和缓存时间
联邦HDFS：由于namenode在内存中储存每个文件和数据块的对应关系，这一定程度制约了HDFS能存储文件的数量。为了缓解这个问题就设置了联邦HDFS，在联邦环境下每个namenode只需要维护一个命名空间卷，由命名空间的元数据和一个数据块池组成。
5. **HDFS文件读取：**
客户端调用FileSystem的open方法来打开希望读取的文件，之后distributedFileSystem会使用RPC来调用namenode以获取文件块的位置。之后对于每个块，namenode都会返回存有该块数据的datanode地址。此外这些datanode距离client的距离也会被计算出来。DistributedFileSystem会返回一个FSDataInputStream对象并封装成DFSinputStream给客户端来方便读取数据。接着客户端会围绕这个输入流多次调用read方法来读取数据。这种设计方法的重要优点是，客户端可以直接连接datanode来读取数据，namenode只是告诉客户端每个块所在的最佳datanode。因此这种设计能使得HDFS扩展到大量的并发客户端，同时这也减轻了namenode的压力。
6. **HDFS文件写入：**
客户端调用create方法来新建文件，分布式文件系统会对namenode创建一个RPC调用，在文件系统的命名空间新建一个文件，此时namenode会执行一系列的检查来确保这个文件不存在，并且客户端具备权限。如果检测通过namenode就会新建一条记录。如果检查不通过，namenode不会创建记录，并抛出一个IOException异常。创建记录成功后也会返回一个FSDataOutPutStream对象给客户端，之后这个对象被封装成为DFSOutPutStream对象，这个对象负责写入操作。在客户端写入数据时，DFSoutputStream会将数据分为一个个的数据包，并写入内部队列，称为数据队列。之后将这些数据写入datanode上。注意DFSoutputStream会维护一个确认队列来收集datanode返回的确认信息。
7. **DataNode写入故障**：
首先关闭管线，把确认队列（ask queue）中的所有数据包都添加回数据队列的最前端，以确保故障结点的下游的datanode不会漏掉任何数据包。为存储在另一正常datanode结点上的当前数据块指定一个新标识，并将该标识传送给namenode，以方便故障datanode恢复后可以删除已经存储的部分数据块。从管线中删除故障datanode，基于正常的datanode新建一条管线，余下的数据块写入管线中正常的datanode中。
8. **数据复本怎么放**
hadoop的默认策略是在运行客户端的结点上放置第一个复本，第二个复本放在同一机架上的结点上。第三个复本与第二个复本位于同一机架。其他复本放在随机的结点上。
